mnist handwritten digit recogniscience vol 313 tion task
jzfeatures

vi hj wij

ð1þ

pretraining

unrolling

fine-tuning

fig
multilayer bencoder[ network

504

28 july 2006

vol 313

science

www
autoencoders typically find poor local minima
extremely broad tuning range required
1000
w2

30 500 rbm

code layer
w4 w3

30
org science vol 313 28 july 2006

505

downloaded
po-

supporting online material
www
recent nonlinear dimensionality reduction algorithm
outperform local linear embedding
506

28 july 2006

vol 313

science

www
decoder

30
w4

500

top rbm
w1
outperformed latent semantic analysis
simplified srr shape assumed
s5 matlab code 20 march 2006
logistic function 1/e1 þ exp
neural information processing systems 17
neural information processing systems 5
first-level rbm remain binary
olivetti face data set
document retrieval method based
reconstruct high-dimensional input vectors
org/cgi/content/full/313/5786/504 supporting online material
purely electric mie resonance
supporting online material
www
bj hj

reports
adjusting
small learning rate achieves 1
science web sites related
fine-tune deep networks efficiently
stochastic real-valued states drawn
produce lower reconstruction errors
rbm_s logistic visible units
multilayer neural network
training higher level rbms
imensionality reduction facilitates
parallel distributed processing
bvi hj àrecon ð2þ
bvi hjàrecon
supporting online material
org

28 july 2006

507

downloaded
brestricted boltzmann machine[
ontario m5s 3g4
2000 commonest word stems
york avenue nw
print issn 0036-8075
finite magnetic-dipole moment
restricted boltzmann machines
symmetrically weighted connections
including high-resolution figures
mnist training set
mnist data set
average squared errors
2 + 2

2000
w1

2000
w1

2000
nonlinear dimensionality reduction
online issn 1095-9203
reported error rates
signal closely scales
selected additional articles
autoencoders give mappings
bvi hj àdata
bvi hjàdata
global finetuning stage
perfect mirror symmetry
extreme nonlinear optics
progressively reveal low-dimensional
true intrinsic dimensionality
learned feature activations
fine-tuning scale linearly
cross-entropy error function
average squared error
backpropagate error derivatives
horizontal incident polarization
shg strongly depends
measured shg signals
nonlinear electron displacement
unlike nonparametric methods
randomly chosen points
binary state hj
stochastic binary values
support vector machines
engineering research council
discover 30dimensional codes
grayscale image patches
principal components analysis
autoencoders produce codes
shg signal strengths
larger shg signal
salakhutdinov high-dimensional data
nonlinear optical properties
features captures strong
srr constituent materials
org/cgi/content/full/313/5786/504#otherarticles information
magnetic field distributions
reuter corpus volume 2
s2 references 26 april 2006
significant shg emission
pretraining helps generalization
similar bdecoder[ network
two-layer network called
fewer feature detectors
synthetic data set
systematic microscopic theory
multiple hidden layers
replaces stochastic activities
usual nonlinear optics
remaining hidden units
logistic output units
six-dimensional deep autoencoder
large data sets
pretraining multiple layers
small central layer
stochastic update rule
incident laser wavelength
test data set
test set documents
vertical incident polarization
shg signal strength
initial weights requires
large initial weights
pretraining greatly reduces
transverse shg polarization
binary feature detectors
feature detectors correspond
pixel intensities lie
hidden units remains
layer-by-layer learning algorithm
randomly initialized backpropagation
article cites 8 articles
linear input units
total training time
random test image
single hidden layer
learn low-dimensional codes
2000 500
w3 w2
supporting material
30dimensional logistic pca
pi log pi ­
small initial weights
deep autoencoder networks
pi log gi^
two-dimensional autoencoder produced
two-dimensional codes found
gradient descent works
unit variance gaussian
handwritten digits
binary vectors
range e0
lithographic tuning
1000 rbm
w3
matlab code
nonlinear autoencoders
decoder network
nonlinear generalization
org/cgi/content/full/313/5786/504#otherarticles
test set
cross-entropy error
higher layers
error derivatives
incident polarization
linear electric
small signal
required gradients
optical properties
deep autoencoders
isi web
learning rate
decoder networks
pretraining algorithm
3 + 3

1000
w2

1000
shg signal
high-dimensional data
highly nonlinear
low-dimensional code
linear optics
neural networks
srr plane
symmetric decoder
produce encoder
update rule
org/cgi/content/full/313/5786/504#related-content
published online 25
fine-tuning stage
test data
incident power
outperformed pca
science online
low-dimensional codes
simplified version
2 articles hosted
mie resonance
shg emission
shg polarization
784-500-500-2000-10 network
network assigns
feature detectors
shallower autoencoders
train autoencoders
data set
real-valued data
binary data
laser wavelength
30dimensional autoencoder
real-valued activities
perfect reconstruction
pixels correspond
remains fixed
transverse component
fast retrieval
hidden layers
initialized correctly
binary pixels
principal components
query document
real-valued probabilities
binary states
shg strength
10 code units
limited information
noise level
hidden units
code spaces
org

downloaded
online version
layer-by-layer pretraining
logistic units
neural comput
single layer
encoder network
electron velocities
steepest descent
oscillator strength
gradient descent
electron micrographs
resources related
lorentz-force field
magnetic component
deep autoencoder
data sets
binary features
nonlinear structure
twodimensional codes
extract codes
code layer
chain rule
energy function
2008

reports
larized
random samples
feature detector
prolonged fine-tuning
visible units
training data
smaller wavelength
3-mm wavelength
linear units
30 linear units
early layers
two-dimensional lsa
learning rule
layer-by-layer learning
shg source
surface shg
training cases
initial weights
visible unit
previous rbm
pretraining consists
codes produced
linear spectrum
srr size
bhidden[ units
bvisible[ units
data point
real data
original data
continuous data
training image
measure similarity
metallic metamaterials
easily obtained
american association
driving force
procedure delivers
ieee trans
blue bars
lorentz force
org/cgi/content/full/313/5786/502/dc1 materials
college road
retrieved documents
accepted 22 june 2006 10
lc resonance
// trec
make good
accepted 1 june 2006 10
speech lang
pixel intensities
continuous variables
highly desirable
metal electrons
alternative route
rights reserved
advanced research
direct comparison
unit cell
activation probabilities
generally good
obtaining reprints
highwire press
slightly adjust
advantage disappears
natural sciences
1b shows
numerically calculate
off-resonant case
selection rules
registered trademark
published weekly
de silva
canadian institute
driving-force vector
leibniz award 2000
500
w4
unit variance
high-order correlations
facilitated comparisons
san mateo
optimal reconstruction
greatest variance
document-specific probabilities
resonance positions
bpretraining[ procedure
morgan kaufmann
mit press
good solution
joint configuration
deutsche forschungsgemeinschaft
obtaining permission
strictly vertical
logistic pca
``logistic pca
top rbm
title science
dtl

science
computer science
updated information
small angle
learning minimized
random weights
rbm encoder
784-pixel image
extra layer
2000500-250-125-2 autoencoder
autoencoder consisted
2000-500-250-125-10 autoencoder
30-dimensional autoencoder
7841000-500-250-2 autoencoder
625-2000-1000-500-30 autoencoder
784-1000-500-250-30 autoencoder
autoencoder discovered
lower bound
represent features
bi vi
small detuning
gaussian noise
standard pca
pca gave
30-dimensional pca
methods figs
/ exdb/mnist/index
square modulus
/ roweis/data
learning works
reports
times
log probability
org/cgi/content/full/313/5786/504/dc1 materials
org/ abs/physics/0601055
parameters increases
helpful discussions
theory tech
hj
quantitative deviations
detection system
spatially averaged
wide variety
real numbers
414 newswire stories
1 + 1

izpixels
shg intensity
000 training images
wij
alternative visualization
model assigns
smaller srrs
bconfabulated[ images
worse reconstructions
class produced
reconstructions produced
weights found
algorithm
online
input
hinton@cs
downloaded
network
vi
autoencoders
stochastic
average
method
set
fine-tune
polarization
small
information
code
dimensionality
related
lower
logistic
codes
2008

reports
find
feature
1127647

www
www
fine-tuning
log
1 ­ pi
^ pi
layers
shg
training
networks
visible
rbm
pretraining
linear
units
``data
data
activities
1 ­ gi
vector
reconstruction
resonance
states
learn
chosen
gaussian
gradient
research
state
documents
18 components
2008

1000

called
vertical
variance
unit
materials
components
usual
reduces
methods
rbms
similar
science 269
science
science 313
science 312
science 290
science 292
science 306
science 303
learning
image
layer
autoencoder
``autoencoder
produced
top
org
features
comput
bj þ
works
noise
bj
encoder
pca
figs
square
volume 1
version
/
references
volume
time
weights
system
updated
org/cgi/content/full/313/5786/504/dc1
averaged
query
4 + 4

2000

500
angle
gradients
numbers
4 + 5
2 + 7
1 + 8
pixel
theory
org/
deviations
3 + 6
parameters
discussions
cs
500 digits
bound
lsa
fast
stories
variety
structure
backpropagation
found
times
probability
size
500 times
class
intensity
visualization
detuning
^ intensity
model
srrs
images
000 images
2008

fig
fig
energy
article
7 article
reconstructions
bi
bi þ
hinton
hinton*
sci
results
eds
generalize
foundations
follow
adding
demonstrate
1980s
demers
labels
desired
summarized
ma
hormann
presented
list
markos
teh
chen
reproduce
brien
current
experiment
kambhatla
apply
3d
jhjwij
lee
perpendicular
free
groups
directions
mcclelland
respect
change
convert
notes
1
classification
explained
prefer
aaas
microw
addressed
decrease
trained
depicted
type
linden
vh-ng-232
robbins
tested
berlin
controlling
springer
smolensky
setup
work
obvious
making
leonhardt
december
cited
sample
allowed
guarantee
soc
shalaev
s1
pp
arrangement
ensemble
schultz
simplicity
dolling
derived
averitt
effective
umstadter
highstrete
padilla
multiclass
satisfied
experiments
plaut
coordinates
initializing
correspondence
1 summarize
introduce
iviwij
half
nature 438
represents
university
2a
2b
2c
pendry
retrieve
weight
express 14
reduce
hjwij
expect
canada
shown
funding
space
rev
hecht-nielsen
adaptive
queries
possibility
langford
rows
veselago
generate
-400-200-10050-25-6
computers
configurations
stewart
``unrolled
number
bunfolded[
1a
1c
1d
calculations
show
dfg
holden
relationship
tool
shallow
part
deterministic
regression
determined
accessed
6 king
curves
well-
manner
recover
shelby
efficient
osindero
-
mechanism
finding
copyright 2006
learns
services
doi
repeated
fact
maksimchuk
supported
confabulations
pretrain
minimizing
1126/science
explain
toronto
/permissions
klein
represented
barlow
fields
//www
nist
saul
close
dc 20005
guyot-sionnest
conditions
comparable
soukoulis
taking
rumelhart
//yann
improves
finds
simple
reconstructs
ca
inf
sciencemag
ensures
raise
create
due
tiny
cosine
treat
interest
expected
tenenbaum
lett
al
bautoencoder[
spirit
applied
harshman
replaced
landauer
identical
nature 173
discrepancy
bias
html
lecun
widely
advances
infeasible
difficult
week
http
driven
koch
changing
roweis
stack
tune
modeled
nonetheless
data--
yen
observed
gov/data/reuters/reuters
hopfield
smith
advancement
natl
excited
details
opt
big
cottrell
leen
moloney
vertically
popov
bcurves[
acad
shen
mcpeake
nature 396
provided
excitation
bottom
resonances
e-mail
welling
proc
measuring
agreement
helmholtz-hochschul-nachwuchsgruppe
biases
//arxiv
optimize
compatible
deerwester
connected
rosen-zvi
á à dwij 0
dumais
raised
cambridge
wegener
communication
bconfabulation[
washington
sov
proportional
reducing
initially
argumentation
transform
fraction
metamaterial
enkrich
non-gaussian
confabulation
usp
ramakrishna
schurig
directed
compute
converted
taylor
activities--
describe
fellow
5 mm
modeling
compared
completeness
furnas
fine-tuned
storage
setting
department
1129198

reducing
phys
zhou
grigorenko
generated
dimensions
starting
1493
1494
33
1842
31
35
44
ð
335
107401
0
6
90
95
96
1995
1997
1999
1998
3966
1
1000
135
2319
24
20
21
22
23
1990
1954
1^
241101
391
87
85
195104
7
þ 0
1993
100%
4%
­
2
653
11
10
13
12
15
14
17
16
19
18
1481­1488
1968
28 â 28
77
20%
79
8254
194­281
8
1982
126
00
01
3
2323
1987
223902
6%
60
64
65
69
2%
509
504
500
1351
402
1860
^
9
892
000
1711
45
1780
804
2­4
1777
4
2554
203901
580­587
1527
2075
1259
207
1986
1127647
*
1200
47
41
5
2002
2000
2001
2006
2004
2005
2008
